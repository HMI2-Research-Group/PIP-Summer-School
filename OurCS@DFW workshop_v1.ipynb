{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.datasets as ds\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.svm as svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture = ['Down', 'Up', 'Left', 'Right']\n",
    "path = 'HeadData/'\n",
    "gyro = '/gyro/'\n",
    "features = 4\n",
    "trials = 40\n",
    "x = [[0] * features for i in range(trials*len(gesture))]\n",
    "y = [0] * trials*len(gesture) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_feature_order(s1,s2):\n",
    "    if (s1>s2): \n",
    "        return 1\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(gesture),1):\n",
    "    for k in range(0,trials,1):\n",
    "        path_data = path+ gesture[i]+ gyro +'trial'+str(k+1)+'.csv'\n",
    "        data = genfromtxt(path_data, delimiter=',')\n",
    "        #Features\n",
    "        x[k+i*trials][0]=min_max_feature_order(np.argmax(data[:,1]), np.argmin(data[:,1]))\n",
    "        x[k+i*trials][1]=min_max_feature_order(np.argmax(data[:,3]), np.argmin(data[:,3]))\n",
    "        x[k+i*trials][2]=min(data[:,1]) # down up gestures the x dimension changes the most\n",
    "        x[k+i*trials][3]=min(data[:,3]) # right left gestures the z dimension changes the most\n",
    "       # x[k+i*trials][4]=max(data[:,1]) # down up gestures the x dimension changes the most\n",
    "       # x[k+i*trials][5]=max(data[:,3]) # right left gestures the z dimension changes the most\n",
    "        # x[k+i*trials][6]=data[:,1].mean() # mean for x dimension\n",
    "        # x[k+i*trials][7]=data[:,3].mean() # mean for z dimension\n",
    "        # x[k+i*trials][8]=data[:,1].std() # std for x dimension\n",
    "        # x[k+i*trials][9]=data[:,3].std() # std for z dimension\n",
    "        #target variables\n",
    "        y[[k+i*trials][0]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 75% training and 25% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x , y, test_size=0.25, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0]\n",
      " [ 0 11  0  0]\n",
      " [ 0  0 11  0]\n",
      " [ 0  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred,  average='micro'))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred,  average='micro'))\n",
    "\n",
    "# Model Confusion Matrix:\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "mean k-Fold cross-validation :  1.0\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator = clf, X = X_train, y = y_train, cv = 4)\n",
    "for i in range (0,4,1):\n",
    "    print (accuracies[i])\n",
    "\n",
    "print ('mean k-Fold cross-validation : ' , accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
